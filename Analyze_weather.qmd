---
title: "Analyze Weather Data"
author: "Alan Jackson"
format: html
editor: visual
---

## Read in and analyze weather data

```{r init}
#| echo: false

library(tidyverse)
library(lubridate)
library(scales)
library(stringr)

path <- "/home/ajackson/Dropbox/Rprojects/Tulane_Solar/Data/"

Weather <- readRDS(paste0(path, "Weather.rds"))

```

## Put data on 15 minute intervals

```{r interpolate}

tz <- "America/Chicago"

xout <- seq(mdy_hm("01-01-2013T00:00", tz=tz),
            mdy_hm("12-31-2022T00:00", tz=tz),
            by=15*60)

Weather_T <- approx(Weather$Date, Weather$Temperature, xout=xout)
Weather_P <- approx(Weather$Date, Weather$Precip, xout=xout)

#   Pick out max cloud cover factor

Weather <- Weather %>% 
  rowwise() %>% 
  mutate(Cloudiness= 
                as.numeric(
                 str_extract(
                 max(
                 unlist(
                 str_extract_all(Sky, ":\\d+"))), "\\d+"))
                 ) %>% 
  ungroup()

Weather_C <- approx(Weather$Date, Weather$Cloudiness, xout=xout)

Weather_trp <- as_tibble(bind_cols(Date=Weather_T$x, 
                    Temperature=Weather_T$y,
                    Precip=Weather_P$y,
                    Cloudiness=Weather_C$y))   

Weather_trp %>%
  head(5000) %>%
  pivot_longer(!Date, names_to="Measurement", values_to="Value") %>% 
  ggplot(aes(x=Date, y=Value, group=Measurement)) +
  facet_wrap(vars(Measurement), scales="free_y")+
  geom_line()

```

## Cloudiness and Precip by week

```{r cloudy}

Weather_trp %>% 
  filter(Precip>0.01) %>% 
  ggplot(aes(x=Precip, y=Cloudiness)) +
  geom_point()

Weather_trp %>% 
    filter(Cloudiness<8.5) %>% 
  filter(Precip>0) %>% 
  mutate(Cloudiness=as.factor(round(Cloudiness))) %>% 
    ggplot(aes(x=log(Precip), y=Cloudiness, fill=stat(x)))+
    ggridges::geom_density_ridges_gradient(scale=2.5)+
    scale_fill_viridis_c(name = "log(Precip (in))", option = "C")+
    labs(title="Log Precipitation vs. Cloudiness",
       subtitle="2013 through 2022",
       x="Log Inches of Precipitation",
       y="Octants Sky Covered by Cloud") 
```

## Do a quick look at correlations with solar output

```{r solar}

#   Dates panels were removed and then replaced
lower <- mdy_hm("08-21-2021T00:00")
upper <- mdy_hm("10-01-2022T23:59")

Solar_old <- readRDS(paste0(path, "Solar_old.rds")) %>% 
  mutate(Solar_W=if_else(between(Timestamp, lower, upper), Solar_W*2, Solar_W))

foo <- left_join(Weather_trp, Solar_old, by=c("Date"="Timestamp")) %>% 
  filter(!is.na(Solar_W))

foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
  filter(between(Hour, 10.9, 13.1)) %>% 
  ggplot(aes(x=Cloudiness, y=Solar_W))+
  geom_point() +
  geom_smooth(method="lm")

foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
  filter(between(Hour, 10.9, 13.1)) %>% 
  ggplot(aes(x=Precip, y=Solar_W))+
  geom_point() +
  geom_smooth(method="lm")

foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
  filter(between(Hour, 10.9, 13.1)) %>% 
  ggplot(aes(x=Temperature, y=Solar_W))+
  geom_point(size=0.1) +
  labs(title="Solar output between 11:00 and 13:00, vs Air Temperature",
       subtitle="May 2019 through December 2022",
       y="kWh",
       x="Air Temperature degrees F") +
  geom_abline(slope=-40, intercept=6500, color="blue")

foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
  filter(between(Hour, 10.9, 13.1)) %>% 
  ggplot(aes(x=Cloudiness, y=Solar_W))+
  geom_point(size=0.1) +
  labs(title="Solar output between 11:00 and 13:00, vs Cloudiness",
       subtitle="May 2019 through December 2022",
       y="kWh",
       x="Octants Sky Covered by Cloud") +
  geom_smooth(method="lm")
  geom_abline(slope=-40, intercept=6500, color="blue")
  
  #   Ridgeline plot
  
tmp <- foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
    filter(Solar_W<6000) %>% 
  filter(between(Hour, 10.99, 13.01)) %>% 
    filter(Cloudiness<8.5) %>% 
  mutate(Cloudiness=as.factor(round(Cloudiness))) %>% 
  group_by(Cloudiness) %>% 
     summarize(Mval=mean(Solar_W)) %>% 
  mutate(Cloudiness=as.numeric(Cloudiness))

tmp <- (predict(lm(tmp$Cloudiness ~ tmp$Mval), 
                new_data=c(0, 4500)))
                #new_data=as_tibble(Mval=seq(0, 4500, 4500))))

#tmp <- as_tibble(bind_cols(Mval=seq(4500, 500, -4000), Cloudiness=tmp))
tmp <- as_tibble(bind_cols(Mval=c(4500, 500), Cloudiness=c(tmp[1], tmp[9])))

  
foo %>% 
  mutate(Hour=hour(Date) + minute(Date)/15*0.25) %>% 
    filter(Solar_W<6000) %>% 
  filter(between(Hour, 10.99, 13.01)) %>% 
    filter(Cloudiness<8.5) %>% 
  mutate(Cloudiness=as.factor(round(Cloudiness))) %>% 
    ggplot(aes(x=Solar_W, y=Cloudiness, fill=stat(x)))+
    ggridges::geom_density_ridges_gradient(scale=3)+
  geom_line(data=tmp, aes(x=Mval, y=Cloudiness))+
    scale_fill_viridis_c(name = "kWh", option = "C")+
    labs(title="Power output vs. Cloudiness, 11:00-13:00",
       subtitle="May 2019 through December 2022",
       x="kWh",
       y="Octants Sky Covered by Cloud") 
    

```

##  Calculate probabilites to save

```{r probability}

foo <- Weather_trp %>% 
  mutate(Hour=hour(Date) + trunc(minute(Date)/15)*0.25) 

#  sums
foo_sum <- foo %>% 
  mutate(Date=date(Date)) %>% 
  group_by(Date, Hour) %>% 
     summarise(AvgD = mean(Dewpoint, na.rm=TRUE),  
               AvgT = mean(Temperature, na.rm=TRUE)) %>%  
  mutate(Temp = case_when(
    AvgT <= 60 ~ "Cold",
    between(AvgT, 60, 70) ~ "Cool",
    between(AvgT, 70, 80) ~ "Warm",
    between(AvgT, 80, 90) ~ "Hot",
    TRUE ~ "Hell"
  )) %>% 
  mutate(Month=month(Date)) %>% 
  mutate(Temp=factor(Temp,
                     levels=c("Cold", "Cool", "Warm", "Hot", "Hell"))) %>% 
    mutate(ToD = case_when(
    Hour <= 6 | Hour >= 19 ~ "Night",
    between(Hour, 16, 19) ~ "Eve",
    TRUE ~ "Day"
  ))  

```


##        Build distributions

```{r functions}

#   https://rdrr.io/github/sethmcg/climod/src/R/pdf2cdf.R
pdf2cdf <- function(p, x=NULL, normalize=TRUE, expand=FALSE){
    if(is.null(x)) {
        if(is.atomic(p)){
            y <- p
            x <- seq(length(y))
        } else {
            stopifnot(exists("x", where=p) && exists("y", where=p))
            y <- p$y
            x <- p$x
        }
    } else {
        stopifnot(is.atomic(p) && is.atomic(x))
        y <- p
    }
    
    stopifnot(length(x)==length(y))
    stopifnot(length(x) > 2)
    stopifnot(all(is.finite(x)))
    stopifnot(all(is.finite(y)))
    stopifnot(all(diff(x) > 0))

    if(any(y < 0)){
        y[y < 0] <- 0
    }
    
    ## trapezoids: N = no., L = left height, R = right height, W = width
    N <- length(y) + 1
    L <- c(0,y)
    R <- c(y,0)
    W <- diff(x)
    W <- c(W[1], W, W[N-2])
    area <- W * (L + R) / 2
    cdf <- cumsum(area)

    if(normalize){
        cdf <- cdf / cdf[N]
    }
    if(expand){
        return(list(x=c(x[1]-W[1],x,x[N-1]+W[N]), y=c(0,cdf)))
    } else {
        return(list(x=x, y=cdf[-N]))
    }
}


make_icdf <- function(foo, offset=0){
  #   density 
  denf = density(foo$AvgT, adjust=1, n=1024)
  #   Convert to CDF
  cdf <- pdf2cdf(denf)
  #   Build data frame
  #dens = data.frame(x=denf$x, y=denf$y)
  #   Build data frame
  cdf <- data.frame(x=denf$x, y=cdf$y)
  #   Spline fit function
  q <- splinefun(cdf$y, cdf$x, method="monoH.FC")
  #   Output points
  probs <- seq(0,1,0.001)
  #   Invert CDF
  icdf <- as_tibble(cbind(AvgT=q(probs)-offset, Prob=probs))
  return(icdf)
}


```


```{r distributions}

foobar <- foo_sum %>% filter(ToD=="Day") %>% 
                      filter(Temp=="Hot") %>% 
                      filter(Month==8)

icdf <- make_icdf(foobar, offset=0)

icdf %>% 
  ggplot(aes(x=AvgT, y=Prob)) +
  geom_line()+
  geom_point()

#   Let's look at density functions first


p <- foo_sum %>% 
  ggplot(aes(x=AvgT, y=ToD, fill=stat(x)))+
  ggridges::geom_density_ridges_gradient(messages=FALSE)+
  scale_fill_viridis_c(name = "Average Hourly Temperature", option = "C")+
  facet_wrap(vars(Month, Temp)) +
  labs(title="Average Hourly Temperature, Time of Day, ")
  
suppressMessages(print(p))

#   Want cumulative probability of bucket as function of Month and Hour

output <- foo_sum %>% 
  mutate(HourOfDay=as.integer(Hour)) %>% 
  group_by(Month, HourOfDay, Temp) %>% 
    summarise(Nbucket=n()) %>% 
  pivot_wider(names_from=Temp, values_from=Nbucket) %>% 
  rowwise() %>% 
  mutate(Total=sum(c(Cold, Cool, Warm, Hot, Hell), na.rm = TRUE)) %>% 
  ungroup() %>% 
  #   Now these are cumulative probabilities
  mutate(Cold=Cold/Total,
         Cool=Cool/Total + Cold,
         Warm=Warm/Total + Cool,
         Hot=Hot/Total + Warm,
         Hell=Hell/Total + Hot)

saveRDS(output, paste0(path, "ICDF_TempBucket_per_Month_Hour.rds"))

```
